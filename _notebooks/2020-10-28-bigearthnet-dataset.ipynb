{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the BigEarthNet dataset\n",
    "> A look at the new BigEarthNet dataset, based on sentinel-2 multispectral images.\n",
    "\n",
    "- toc: true\n",
    "- hide: false\n",
    "- search_exclude: false\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "In the previous post, [understanding spectral reflectance](https://kai-tub.github.io/master-thesis-blog/images/2020/10/14/understanding-spectral-reflectance.html), we saw that objects could be differentiated by their surface reflectance. The surface reflectance can be sensed as multi-spectral images from satellites. In the following post, we will examine the Sentinel-2 mission and the resulting data. Afterwards, we will review an example remote sensing dataset, BigEarthNet.\n",
    "\n",
    "## Sentinel-2 mission\n",
    "[Sentinel-2](https://en.wikipedia.org/wiki/Sentinel-2) is an earth-observation mission and consists of two satellites\n",
    "Sentinel-2A and Sentinel-2B. Both of which are operated by the European Space Agency ([ESA](https://en.wikipedia.org/wiki/European_Space_Agency)). The task is to gather multi-spectral data for climate change, agriculture monitoring, and emergency management. The data is published under a free and open data policy, making it valuable for academic purposes.\n",
    "\n",
    "<figure>\n",
    "        <div>\n",
    "            <figure>\n",
    "<img src=\"2020-10-28/Sentinel-2.jpeg\" alt=\"Picture of a Sentinel-2 satellite\">\n",
    "            </figure>\n",
    "        </div>\n",
    "    <figcaption><center>Fig 1: A Sentinel-2 satellite<a href=\"https://www.satimagingcorp.com/satellite-sensors/other-satellite-sensors/sentinel-2a/\">(Image from Satellite Imaging Corporation)</a></center></figcaption>\n",
    "</figure>\n",
    "\n",
    "With both satellites and their large field of view (290km), they can sense most of the earth's land cover every 5 days. \n",
    "The revisit frequency is also called the temporal resolution.\n",
    "The spatial resolution is reported as $XX\\,\\text{m}$, which refers to the length and height of a pixel. So a resolution of 10m would correspond to a single pixel capturing an area of 10m x 10m, or 100mÂ². An example remote sensing image can be seen in the following figure. The Sentinel-2 satellites have a spatial resolution of 10m (four visible and near-infrared), 20m (six red edge and short-wave infrared), and 60m (three atmospheric correction) bands. {% cite Sentinel2SpatialResolution %}\n",
    "\n",
    "<figure>\n",
    "        <div>\n",
    "            <figure>\n",
    "<img src=\"2020-10-28/landsat-resolution.jpg\" alt=\"Visualization of spatial resolution with 30m band\">\n",
    "            </figure>\n",
    "        </div>\n",
    "    <figcaption><center>Example remote sensing image with a 30m spatial resolution (<a href=\"http://gsp.humboldt.edu/OLM/Courses/GSP_216_Online/lesson3-1/resolution.html#:~:text=Spatial%20resolution%20is%20usually%20reported,side%20of%20a%20single%20pixel.&text=In%20other%20words%2C%20an%20image,that%20is%2030%20meters%20across.\">Image from GSP Humboldt</a>)</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "In total, thirteen bands are sensed, ranging from the visible/near-infrared (VNIR) to the short-wave infrared (SWIR) spectrum. Each band has effectively 16-bits per channel, or as it is commonly referred to in the remote image sensing community, a *radiometric resolution* of 16-bits. The term *radiometric resolution* highlights the domain in which the images are used but is no different from _bits per channel_{% fn 1 %}.\n",
    "\n",
    "The following figure shows all thirteen bands grouped by their spatial resolution.\n",
    "ESA introduced Band _8A_ in the Sentinel-2 mission as band 08 was too contaminated by water vapor and insensitive to other parameters for some applications. But, the original sensor for band 08 remained in the sensory equipment. \n",
    "The narrowness of band 8A should make the results less noisy towards water vapor but still be wide enough for most applications {% cite Sentinel2Heritage %}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/resolutions/radiometric\n",
    "# Usage from http://esamultimedia.esa.int/multimedia/publications/SP-1322_2/offline/download.pdf\n",
    "sentinel_band_data = pd.DataFrame([\n",
    "    {\n",
    "        \"Band\": \"02\",\n",
    "        \"Central Wavelength\": 492,\n",
    "        \"Bandwidth\": 66,\n",
    "        \"Spatial Resolution\": \"10m\",\n",
    "        \"Usage\": \"Blue Channel (RGB)\",\n",
    "        \"Color\": \"navy\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"03\",\n",
    "        \"Central Wavelength\": 560,\n",
    "        \"Bandwidth\": 36,\n",
    "        \"Spatial Resolution\": \"10m\",\n",
    "        \"Usage\": \"Green Channel (RGB)\",\n",
    "        \"Color\": \"green\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"04\",\n",
    "        \"Central Wavelength\": 665,\n",
    "        \"Bandwidth\": 31,\n",
    "        \"Spatial Resolution\": \"10m\",\n",
    "        \"Usage\": \"Red Channel (RGB)\",\n",
    "        \"Color\": \"red\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"08\",\n",
    "        \"Central Wavelength\": 833,\n",
    "        \"Bandwidth\": 106,\n",
    "        \"Spatial Resolution\": \"10m\",\n",
    "        \"Usage\": \"Vegetation Red-Edge\",\n",
    "        \"Color\": \"darkred\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"05\",\n",
    "        \"Central Wavelength\": 704,\n",
    "        \"Bandwidth\": 15,\n",
    "        \"Spatial Resolution\": \"20m\",\n",
    "        \"Usage\": \"Vegetation Red-Edge\",\n",
    "        \"Color\": \"salmon\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"06\",\n",
    "        \"Central Wavelength\": 740,\n",
    "        \"Bandwidth\": 15,\n",
    "        \"Spatial Resolution\": \"20m\",\n",
    "        \"Usage\": \"Vegetation Red-Edge\",\n",
    "        \"Color\": \"lightcoral\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"07\",\n",
    "        \"Central Wavelength\": 780,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"Spatial Resolution\": \"20m\",\n",
    "        \"Usage\": \"Vegetation Red-Edge\",\n",
    "        \"Color\": \"palevioletred\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"08a\",\n",
    "        \"Central Wavelength\": 865,\n",
    "        \"Bandwidth\": 21,\n",
    "        \"Spatial Resolution\": \"20m\",\n",
    "        \"Usage\": \"Vegetation Red-Edge\",\n",
    "        \"Color\": \"indianred\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"11\",\n",
    "        \"Central Wavelength\": 1612,\n",
    "        \"Bandwidth\": 91,\n",
    "        \"Spatial Resolution\": \"20m\",\n",
    "        \"Usage\": \"Snow/Ice/Cloud Discrimination\",\n",
    "        \"Color\": \"gray\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"12\",\n",
    "        \"Central Wavelength\": 2195,\n",
    "        \"Bandwidth\": 175,\n",
    "        \"Spatial Resolution\": \"20m\",\n",
    "        \"Usage\": \"Snow/Ice/Cloud Discrimination\",\n",
    "        \"Color\": \"darkgray\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"01\",\n",
    "        \"Central Wavelength\": 443,\n",
    "        \"Bandwidth\": 21,\n",
    "        \"Spatial Resolution\": \"30m\",\n",
    "        \"Usage\": \"Aerosols\",\n",
    "        \"Color\": \"lightblue\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"09\",\n",
    "        \"Central Wavelength\": 944,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"Spatial Resolution\": \"30m\",\n",
    "        \"Usage\": \"Water-Vapor\",\n",
    "        \"Color\": \"lightsteelblue\"\n",
    "    },\n",
    "    {\n",
    "        \"Band\": \"10\",\n",
    "        \"Central Wavelength\": 1375,\n",
    "        \"Bandwidth\": 31,\n",
    "        \"Spatial Resolution\": \"30m\",\n",
    "        \"Usage\": \"Cirrus\",\n",
    "        \"Color\": \"lightgray\"\n",
    "    },\n",
    "]).sort_values(\"Band\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-376bc43c7d9643bfb50faaf56634f82f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-376bc43c7d9643bfb50faaf56634f82f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-376bc43c7d9643bfb50faaf56634f82f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-db9f70adba471f174030643a7ad8ef04\"}, \"facet\": {\"row\": {\"type\": \"nominal\", \"field\": \"Spatial Resolution\"}}, \"spec\": {\"mark\": \"rect\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Color\", \"scale\": null}, \"tooltip\": [{\"type\": \"ordinal\", \"field\": \"Band\", \"title\": \"Band\"}, {\"type\": \"nominal\", \"field\": \"Usage\"}, {\"type\": \"quantitative\", \"field\": \"Central Wavelength\"}, {\"type\": \"nominal\", \"field\": \"Spatial Resolution\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"start\", \"title\": \"Wavelength in nm\"}, \"x2\": {\"field\": \"end\"}}, \"height\": 100, \"transform\": [{\"calculate\": \"datum['Central Wavelength'] - 1/2 * datum['Bandwidth']\", \"as\": \"start\"}, {\"calculate\": \"datum['Central Wavelength'] + 1/2 * datum['Bandwidth']\", \"as\": \"end\"}], \"width\": 600}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-db9f70adba471f174030643a7ad8ef04\": [{\"Band\": \"01\", \"Central Wavelength\": 443, \"Bandwidth\": 21, \"Spatial Resolution\": \"30m\", \"Usage\": \"Aerosols\", \"Color\": \"lightblue\"}, {\"Band\": \"02\", \"Central Wavelength\": 492, \"Bandwidth\": 66, \"Spatial Resolution\": \"10m\", \"Usage\": \"Blue Channel (RGB)\", \"Color\": \"navy\"}, {\"Band\": \"03\", \"Central Wavelength\": 560, \"Bandwidth\": 36, \"Spatial Resolution\": \"10m\", \"Usage\": \"Green Channel (RGB)\", \"Color\": \"green\"}, {\"Band\": \"04\", \"Central Wavelength\": 665, \"Bandwidth\": 31, \"Spatial Resolution\": \"10m\", \"Usage\": \"Red Channel (RGB)\", \"Color\": \"red\"}, {\"Band\": \"05\", \"Central Wavelength\": 704, \"Bandwidth\": 15, \"Spatial Resolution\": \"20m\", \"Usage\": \"Vegetation Red-Edge\", \"Color\": \"salmon\"}, {\"Band\": \"06\", \"Central Wavelength\": 740, \"Bandwidth\": 15, \"Spatial Resolution\": \"20m\", \"Usage\": \"Vegetation Red-Edge\", \"Color\": \"lightcoral\"}, {\"Band\": \"07\", \"Central Wavelength\": 780, \"Bandwidth\": 20, \"Spatial Resolution\": \"20m\", \"Usage\": \"Vegetation Red-Edge\", \"Color\": \"palevioletred\"}, {\"Band\": \"08\", \"Central Wavelength\": 833, \"Bandwidth\": 106, \"Spatial Resolution\": \"10m\", \"Usage\": \"Vegetation Red-Edge\", \"Color\": \"darkred\"}, {\"Band\": \"08a\", \"Central Wavelength\": 865, \"Bandwidth\": 21, \"Spatial Resolution\": \"20m\", \"Usage\": \"Vegetation Red-Edge\", \"Color\": \"indianred\"}, {\"Band\": \"09\", \"Central Wavelength\": 944, \"Bandwidth\": 20, \"Spatial Resolution\": \"30m\", \"Usage\": \"Water-Vapour\", \"Color\": \"lightsteelblue\"}, {\"Band\": \"10\", \"Central Wavelength\": 1375, \"Bandwidth\": 31, \"Spatial Resolution\": \"30m\", \"Usage\": \"Cirrus\", \"Color\": \"lightgray\"}, {\"Band\": \"11\", \"Central Wavelength\": 1612, \"Bandwidth\": 91, \"Spatial Resolution\": \"20m\", \"Usage\": \"Snow/Ice/Cloud Discrimination\", \"Color\": \"gray\"}, {\"Band\": \"12\", \"Central Wavelength\": 2195, \"Bandwidth\": 175, \"Spatial Resolution\": \"20m\", \"Usage\": \"Snow/Ice/Cloud Discrimination\", \"Color\": \"darkgray\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse\n",
    "alt.Chart(sentinel_band_data).mark_rect().encode(\n",
    "    x=alt.X(\"start:Q\", title=\"Wavelength in nm\"),\n",
    "    x2=\"end:Q\",\n",
    "#     color=alt.Color(\"Band\", scale=alt.Scale(scheme=\"category20\")),\n",
    "    color=alt.Color(\"Color\", scale=None),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"Band:O\", title=\"Band\"),\n",
    "        alt.Tooltip(\"Usage\"), \n",
    "        alt.Tooltip(\"Central Wavelength\"),\n",
    "        alt.Tooltip(\"Spatial Resolution\"), \n",
    "    ]\n",
    ").transform_calculate(\n",
    "    start=\"datum['Central Wavelength'] - 1/2 * datum['Bandwidth']\",\n",
    "    end=\"datum['Central Wavelength'] + 1/2 * datum['Bandwidth']\"\n",
    ").properties(\n",
    "    height=100,\n",
    "    width=600\n",
    ").facet(\n",
    "    row=\"Spatial Resolution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyone can register on [scihub.copernicus.eu](https://scihub.copernicus.eu/) and search for remote sensing imagery.\n",
    "The images, also called tiles or granules, from the Sentinel-2 mission sense an area of 100kmÂ² and are ~600MB in size. {% cite Sentinel2Products %} The Copernicus program provides two types of data for public usage: \n",
    "- L2A (Level 2A with atmospheric correction)\n",
    "- L1C (Level 1C without atmospheric correction)\n",
    "\n",
    "Applying atmospheric correction algorithms transform a so-called TOA (Top Of Atmosphere) to a BOA (Bottom Of Atmosphere) image.\n",
    "If one is interested in the surface reflectance values, or more generally on the objects on the ground, the L2A data should be preferred. In the case of missing L2A data, the [Sentinel-2 toolbox](https://earth.esa.int/web/sentinel/toolboxes/sentinel-2) can be used to generate L2A from L1C images.\n",
    "\n",
    "<figure>\n",
    "    <div style=\"display: flex; flex-wrap: wrap; justify-content: center\">\n",
    "        <div>\n",
    "            <figure id=\"Fig2a\">\n",
    "<img src=\"2020-10-28/T59GPP_20200119T222541_TCI.jpg\" alt=\"Sentinel-2 example image (true-color)\">\n",
    "            <figcaption><center>a) True-color image</center></figcaption>\n",
    "            </figure>\n",
    "        </div>\n",
    "        <div>\n",
    "            <figure id=\"Fig2b\">\n",
    "<img src=\"2020-10-28/T59GPP_20200119T222541_FalseColor.jpg\" alt=\"Sentinel-2 example image (false-color)\">\n",
    "            <figcaption><center>b) False-color composition</center></figcaption>\n",
    "            </figure>\n",
    "        </div>\n",
    "    </div>\n",
    "    <figcaption><center>Fig 2: Sentinel-2 example image</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "<a href=\"#Fig2a\">Fig. 2a</a> shows the visible bands of a randomly selected image with low cloud coverage. Remote sensing images that show the visible bands, like classic RGB images are called _true-color images_ (TCI).\n",
    "To visualize the data from the other bands one can:\n",
    "1. Show each band independently as a grayscale image\n",
    "2. Map three bands to the classic _RGB_ channels of an image (called false-color image/composite)\n",
    "\n",
    "<a href=\"#Fig2b\">Fig. 2b</a> shows a popular false-color composite, using the bands 08, 04, and 03.\n",
    "With the band in the near-infrared spectrum (band 08) as the *red* channel, the healthy green vegetation will light up in bright red. As the bare soil has a low reflectance in the near-infrared spectrum, it will range from tan to turquoise.\n",
    "With the [EO Browser](https://apps.sentinel-hub.com/eo-browser/?zoom=10&lat=41.89972&lng=12.49969&themeId=DEFAULT-THEME), you can interact with satellite imagery and false-color composites without requiring you to download any images or manually applying transformations on different spectral bands.\n",
    "\n",
    "> Note: I highly recommend playing around with the [EO Browser](https://apps.sentinel-hub.com/eo-browser/?zoom=10&lat=41.89972&lng=12.49969&themeId=DEFAULT-THEME) as it is the easiest way to interact with the various bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get most of the high-volume data from remote sensing images, one can employ deep-learning.\n",
    "Deep-learning has become the state-of-the-art solution to complex computer vision applications.\n",
    "Usually, deep-learning models are used on classic RGB images, but they also seem to be promising for these multi-spectral images. To train and test these models, researchers need large, high-quality datasets.\n",
    "The data assembly was not a problem, thanks to the open data policy of the Sentinel-2 imagery.\n",
    "Sumbul *et. al* {% cite Sumbul2019 %} were able to assemble and published such a dataset, [BigEarthNet](http://bigearth.net/).\n",
    "\n",
    "## BigEarthNet\n",
    "The BigEarthNet archive uses Sentinel-2 tiles that are distributed over 10 countries from Europe {% fn 2 %}.\n",
    "Only tiles with a cloud cover percentage under 1% containing no missing/faulty pixels were considered. The tiles were then split into smaller non-overlapping patches for further processing and publication.\n",
    "In total, the dataset consists of 590,326 patches, each of which covers a region of 1.200m x 1.200m.\n",
    "Due to the different spatial resolution of the various bands, the patches have different sizes. 120 x 120 pixels for 10m bands, 60 x 60 pixels for 20m bands, and 20 x 20 pixels for 60m bands.\n",
    "\n",
    "As the archive is based on Sentinel-2 images, the radiometric resolution is 16-bits.\n",
    "The time-frame for the acquisition dates were between June 2017 $-$ June 2018. Due to the winter months generally having\n",
    "higher cloud coverages, the winter season has the fewest samples, as seen in the following chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-c68369415fe24781bea53efba8e2f2c2\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-c68369415fe24781bea53efba8e2f2c2\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-c68369415fe24781bea53efba8e2f2c2\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-5f998322fef9fae3a2f186fbce23f9c7\"}, \"mark\": \"bar\", \"encoding\": {\"tooltip\": [{\"type\": \"nominal\", \"field\": \"Season\"}, {\"type\": \"quantitative\", \"field\": \"# Images\"}], \"x\": {\"type\": \"nominal\", \"field\": \"Season\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"# Images\"}}, \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-5f998322fef9fae3a2f186fbce23f9c7\": [{\"Season\": \"Autumn\", \"# Images\": 154943}, {\"Season\": \"Winter\", \"# Images\": 117156}, {\"Season\": \"Spring\", \"# Images\": 189276}, {\"Season\": \"Summer\", \"# Images\": 128951}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse\n",
    "season_data = pd.DataFrame([\n",
    "    {\"Season\": \"Autumn\", \"# Images\": 154_943},\n",
    "    {\"Season\": \"Winter\", \"# Images\": 117_156},\n",
    "    {\"Season\": \"Spring\", \"# Images\": 189_276},\n",
    "    {\"Season\": \"Summer\", \"# Images\": 128_951},\n",
    "])\n",
    "\n",
    "alt.Chart(season_data).mark_bar().encode(\n",
    "    x=\"Season\",\n",
    "    y=\"# Images\",\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"Season\"),\n",
    "        alt.Tooltip(\"# Images\"), \n",
    "    ],\n",
    ").properties(\n",
    "    width=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors identified [70,987 patches](http://bigearth.net/#downloads) that are fully covered by clouds, cloud shadows, and seasonal snow. They provide CSV files to exclude these patches if desired and recommend to do so if neural networks are only trained on the BigEarthNet dataset.\n",
    "\n",
    "The last point to note is that not all bands are used in this dataset; band 10 is omitted. Band 10 does not include any surface-level information, as it is mainly used to detect cirrus clouds {% cite Sentinel2CloudMasks %}. These clouds form at high altitudes and are transparent or semi-transparent in the optical bands but have a high impact on the _original_ spectral reflectance {% cite Qiu2020 %}. For the data preprocessing step, the 10th band is a significant indicator of the data quality but does not hold any information for down-stream processes. \n",
    "To use the correct terminology, band 10 is important for TOA analysis and the conversion from TOA to BOA images.\n",
    "However, the other 60m bands used for atmospheric correction were not removed.\n",
    "\n",
    "With that said, we have covered all the essential details of the BigEarthNet archive. But, before we move on and use the dataset, let's take a short recap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The most important features of the Sentinel-2 earth-observation mission are:\n",
    "- 2 satellites (Sentinel-2A/Sentinel-2B)\n",
    "- Temporal resolution of 5 days\n",
    "- Spatial resolution of 10m, 20m, and 30m (depending on the specific band)\n",
    "- Radiometric resolution of 16-bits\n",
    "- Senses 13 bands, from the visible/near-infrared to the short-wave infrared spectrum\n",
    "- Open data policy\n",
    "\n",
    "Thanks to the open data policy, researchers were able to create _BigEarthNet_, a large, freely available multi-spectral dataset for deep-learning. The significant properties are:\n",
    "- Provides ~590,000 patches\n",
    "    - Each patch covers a region of 1.200m x 1.200m\n",
    "- Various resolutions defined by Sentinel-2 specs\n",
    "- Does not include band 10, as it does not contain surface-level information\n",
    "- Provides CSV with all _uninformative_ patches (patch with only snow/clouds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "{% bibliography --cited_in_order %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{ 'There is some ambiguity of the actual *radiometric resolution*. The [official website](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/resolutions/radiometric) writes a radiometric resolution of 12-bits per channel, but the information is out of date. [Inspection of images](https://gis.stackexchange.com/questions/233874/what-is-the-range-of-values-of-sentinel-2-level-2a-images) starting around 2016 reveals a resolution of at least 15-bits. But the full 16-bit range is used to encode special values. As the data will always end-up using 2 Bytes for storage (16-bits), it is commonly treated as a 16-bit image. I tried my best to comprehend the data range fully, but there are still some open questions. I am trying to answer these questions and have an open discussion on [gis.stackexchange.com](https://gis.stackexchange.com/questions/376711/understanding-value-range-for-sentinel-2-images). Feel free to join the discussion!' | fndetail: 1 }}\n",
    "\n",
    "{{ 'These 10 countries are: Austria, Belgium, Finland, Ireland, Kosovo, Lithuania, Luxembourg, Portugal, Serbia, Switzerland' | fndetail: 2 }}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
