<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://kai-tub.github.io/master-thesis-blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://kai-tub.github.io/master-thesis-blog/" rel="alternate" type="text/html" /><updated>2020-10-05T02:28:46-05:00</updated><id>https://kai-tub.github.io/master-thesis-blog/feed.xml</id><title type="html">Kai’s Master Thesis Blog</title><subtitle>Remote image sensing and self-supervision master thesis blog</subtitle><entry><title type="html">Color widgets</title><link href="https://kai-tub.github.io/master-thesis-blog/widgets/2020/10/04/color-widgets.html" rel="alternate" type="text/html" title="Color widgets" /><published>2020-10-04T00:00:00-05:00</published><updated>2020-10-04T00:00:00-05:00</updated><id>https://kai-tub.github.io/master-thesis-blog/widgets/2020/10/04/color-widgets</id><content type="html" xml:base="https://kai-tub.github.io/master-thesis-blog/widgets/2020/10/04/color-widgets.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-10-04-color-widgets.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;About&quot;&gt;About&lt;a class=&quot;anchor-link&quot; href=&quot;#About&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;In the previous two posts we looked at grayscale images, which used a single channel, RGB images with three channels and at multi-spectral images with various channels. I provided &lt;em&gt;Python&lt;/em&gt; image generating code so you could copy and execute the code locally or run the notebook via the badges on &lt;em&gt;binder&lt;/em&gt; or &lt;em&gt;Colab&lt;/em&gt;. Although, this could be valueable for people with the relevant background knowledge or extra time, it may leave out some people.
In my opinion, it is crucial to visualize and interact with technical topics to get a &lt;em&gt;better feel&lt;/em&gt; for it or to be able to look at it from a different angle.&lt;/p&gt;
&lt;p&gt;Therefore, I will try to introduce some &lt;em&gt;widgets&lt;/em&gt; from time to time.
Due to hosting limitations, these will be slow and may not look as polished &lt;em&gt;but&lt;/em&gt; they are free of charge for me and allow you to interact with the written widgets. :)&lt;/p&gt;
&lt;p&gt;It took me some time to find a viable solution, so I will show both widgets here for quick access, but I will also add them to the previous posts.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;iframe src=&quot;../../../../../nb.html&quot; title=&quot;Inline interactive notebook&quot; allowfullscreen=&quot;true&quot; width=&quot;100%&quot; height=&quot;750&quot; seamless=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;iframe src=&quot;https://kai-tub.github.io/test-nbinteract/binder/nb.html&quot; title=&quot;Inline interactive notebook&quot; allowfullscreen=&quot;true&quot; width=&quot;100%&quot; height=&quot;750&quot; seamless=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;iframe src=&quot;../../../../../index.html&quot; title=&quot;Inline interactive notebook&quot; allowfullscreen=&quot;true&quot; width=&quot;100%&quot; height=&quot;750&quot; seamless=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Introduction to multi-channel images</title><link href="https://kai-tub.github.io/master-thesis-blog/images/2020/09/16/images-with-channels.html" rel="alternate" type="text/html" title="Introduction to multi-channel images" /><published>2020-09-16T00:00:00-05:00</published><updated>2020-09-16T00:00:00-05:00</updated><id>https://kai-tub.github.io/master-thesis-blog/images/2020/09/16/images-with-channels</id><content type="html" xml:base="https://kai-tub.github.io/master-thesis-blog/images/2020/09/16/images-with-channels.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-16-images-with-channels.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;About&quot;&gt;About&lt;a class=&quot;anchor-link&quot; href=&quot;#About&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;In the previous &lt;a href=&quot;https://kai-tub.github.io/master-thesis-blog/images/2020/09/02/introduction.html&quot;&gt;post&lt;/a&gt;, 
we took a closer look at grayscale images and how they are encoded on the computer. But these types of images are boring... 
Images with color are nicer to look at and carry more information for us. In the following, we will examine RGB images and what the difference is between those images and multi-spectral images.&lt;/p&gt;
&lt;h2 id=&quot;Short-recap:-Grayscale-images&quot;&gt;Short recap: Grayscale images&lt;a class=&quot;anchor-link&quot; href=&quot;#Short-recap:-Grayscale-images&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;To summarize our findings from the previous &lt;a href=&quot;https://kai-tub.github.io/master-thesis-blog/images/2020/09/02/introduction.html&quot;&gt;post&lt;/a&gt;: We have seen that every image consists of pixels. These pixels are nothing more than numbers stored as binary values on the disk. Depending on how many bits we use per pixel, we can tune the number of distinct colors (color-depth). Besides adjusting the color-depth, we also tuned the resolution. With a higher resolution, we can show &lt;em&gt;more details&lt;/em&gt;. Remember, with a single pixel, we can only encode a single color, but with many pixels, we can capture scenes and objects!&lt;/p&gt;
&lt;h2 id=&quot;RGB-images&quot;&gt;RGB images&lt;a class=&quot;anchor-link&quot; href=&quot;#RGB-images&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;So how do we add color information to our images? If we think back to art class, we may remember &lt;a href=&quot;https://en.wikipedia.org/wiki/Primary_color&quot;&gt;&lt;em&gt;primary colors&lt;/em&gt;&lt;/a&gt;. Red, green, and blue can be combined to create any color. Because we work with displays and light emitting from them, we &lt;em&gt;additively mix&lt;/em&gt; the primary colors.&lt;sup id=&quot;fnref-1&quot; class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn-1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; Each of these three colors has its own &lt;em&gt;channel&lt;/em&gt;. In the previous grayscale examples, there was only a single channel for our gray values.
Now we use three channels instead of one. These three channels are &lt;em&gt;combined&lt;/em&gt; and presented to us in an additive manner. 
A close-up image of an LCD screen helps us to understand how we &lt;em&gt;create&lt;/em&gt; colors on our screen.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;figure&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/LCD_pixels_RGB.jpg&quot; alt=&quot;LCD subpixels&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;/figure&gt;
        &lt;/div&gt;
    &lt;figcaption&gt;&lt;center&gt;Subpixels of an LCD monitor &lt;a href=&quot;https://en.wikipedia.org/wiki/Primary_color#/media/File:LCD_pixels_RGB.jpg&quot;&gt;(Image from Robnil01, Wikimedia)&lt;/a&gt;&lt;/center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;p&gt;Our color values are once again only binary values on our disk. But if we show them on our LCD screen, each pixel has a red, green, and blue &lt;em&gt;subpixel&lt;/em&gt;, which are combined to show us the color we want. Now let's start to program and see if we can &lt;em&gt;mix&lt;/em&gt; some colors with Python!
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;Now there are different places where we could &lt;em&gt;put&lt;/em&gt; the color channel dimension. Sadly, almost every library has a different definition of where the color channel, height, and width dimension should be. So always check the library you are using to see how you should lay out the data. Otherwise, you will not get the results you expect! PIL assumes  the following order: W x H x C
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;PIL&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageOps&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;to_rgb_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;RGB&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;upscale_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEAREST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Let&amp;#39;s start with a single pixel but with three channels!&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Btw do not forget to set dtype, otherwise the colors will be wrong ;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;img_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;pixel_red&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;pixel_green&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;pixel_blue&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_rgb_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upscale_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bordered_img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageOps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;border&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;black&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;figure&gt;
    &lt;div style=&quot;display: flex; flex-wrap: wrap; justify-content: center&quot;&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/pixel_red.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;Channel 0 -- Red&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/pixel_green.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;Channel 1 -- Green&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/pixel_blue.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;Channel 2 -- Blue&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;figcaption&gt;&lt;center&gt;Visualization of primary color pixels&lt;/center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Now that we have the three primary colors, we can mix them to get almost any color!
Here are some examples:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pixel_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;black&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;red_and_green&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;green_and_blue&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;all_150&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_val&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pixel_values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_rgb_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upscale_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bordered_img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageOps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;border&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;black&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;figure&gt;
    &lt;div style=&quot;display: flex; flex-wrap: wrap; justify-content: center&quot;&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/black.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;All values 0&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/white.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;All values 255&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/all_150.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;All values 150&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/red_and_green.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;Red &amp;amp; Green 255&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/green_and_blue.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;Green &amp;amp; Blue 255&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;figcaption&gt;&lt;center&gt;Visualization of different color values&lt;/center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;If we don't limit ourselves to a single pixel, we can visualize vibrant images, showing us many different objects and scenes. With the extra color information, we can more easily differentiate objects, like flowers or fruits.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;figure&gt;
    &lt;div style=&quot;display: flex; flex-wrap: wrap; justify-content: center&quot;&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/flowers_gray.jpg&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;Grayscale image&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/flowers.jpg&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;RGB image&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;figcaption&gt;&lt;center&gt;Image with RGB colors vs. grayscale image&lt;/center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;In the computer vision field, most architectures also work with RGB images. These are the types of images we usually use for everything. The extra color information helps machine learning researches to increase the accuracy of the predictions further. It seems reasonable for us humans to assume that color information improves the prediction performance because it is easier to identify objects if we add color to the image. But for the computer, these are once again nothing more than 0s and 1s. So what would happen if we add more channels?&lt;/p&gt;
&lt;p&gt;Before we move on, let's summarize what we have learned so far.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Summary&quot;&gt;Summary&lt;a class=&quot;anchor-link&quot; href=&quot;#Summary&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;To summarize the previous section: The LCD screens we are looking at combine red, green, and blue subpixels in each pixel to transform the binary values into colors. These three colors are used because they are primary colors and can be additively combined to create any color. On disk, these values are still nothing more than binary numbers. But now we have three channels and, therefore, three times as many bytes per image compared to a grayscale image. For a 28 x 28 pixels image, we now have 28 x 28 x 3 x color-depth bytes. The extra color information helps us (and neural networks) to identify and differentiate objects.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Introduction-to-remote-sensing-images&quot;&gt;Introduction to remote sensing images&lt;a class=&quot;anchor-link&quot; href=&quot;#Introduction-to-remote-sensing-images&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In the previous section, we saw how different a grayscale image looks from an RGB image and that it is easier for us to identify and differentiate colored objects. The same holds for neural networks! In the computer vision setting, images are used as input, and the network takes some &lt;em&gt;action&lt;/em&gt; based on it. For example, we could use it to predict a specific class (dog or cat) or transform the picture (remove people from the scenery). But what would happen if we add more channels? Would the prediction performance still increase?&lt;/p&gt;
&lt;p&gt;In a field called &lt;em&gt;remote sensing&lt;/em&gt;  we sometimes use &lt;em&gt;multi-spectral&lt;/em&gt; images as input images. 
After &lt;a href=&quot;https://en.wikipedia.org/wiki/Remote_sensing&quot;&gt;Wikipedia&lt;/a&gt;, remote sensing is:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;In current usage, the term &quot;remote sensing&quot; generally refers to the use of satellite or aircraft-based sensor technologies to detect and classify objects on Earth.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So the images used in remote sensing could be classic RGB images from drones used to classify different objects.
Here the classes could be building, car, forest, water, fields, etc.
With the introduction of &lt;em&gt;Deep Learning&lt;/em&gt; and neural networks in the field, the processing of a different image type is gaining popularity:multi-spectral images.
To answer what multi-spectral images are, let's take a step back and think about how our RGB images are displayed on an LCD screen. We know that each pixel uses subpixels to &lt;em&gt;add&lt;/em&gt; them together to a color. The subpixel &lt;em&gt;shines&lt;/em&gt; in a single color.
More accurately, the subpixel emits &lt;em&gt;electromagnetic waves&lt;/em&gt; in a specific wavelength in the spectrum of visible light. Here, &lt;em&gt;visible&lt;/em&gt; refers to a spectrum we humans can perceive.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;figure&gt;
    &lt;div style=&quot;display: flex; flex-wrap: wrap; justify-content: center&quot;&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-16/bands.png&quot; alt=&quot;Light spectrum&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;Electromagnetic spectrum &lt;a href=&quot;https://en.wikipedia.org/wiki/Electromagnetic_spectrum&quot;&gt;(Image from Wikipedia)&lt;/a&gt;&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
    &lt;/div&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;A blue subpixel mostly emits an electromagnetic wave with a wavelength of around 470nm, which we perceive as blue. That means that the LCD screen does not &lt;em&gt;add&lt;/em&gt; the different wavelengths together in some way, it only drives the subpixels differently, and for our eyes, it seems like the light of the subpixels have been combined to a specific color. As we have seen previously, if we zoom in on an LCD
screen, we can differentiate the subpixels' primary colors again.&lt;/p&gt;
&lt;p&gt;If our LCD screen would only emit electromagnetic waves outside of the visible spectrum, it would be of little benefit to us humans.
But visualizing bands that we aren't able to see is quite helpful! A well-known use case is &lt;a href=&quot;https://en.wikipedia.org/wiki/Thermography&quot;&gt;thermal imaging&lt;/a&gt;. Here the long-infrared band is detected or &lt;em&gt;sensed&lt;/em&gt; and visualized. The long-infrared band shows us the temperature variations, even if the objects aren't visible to us. The following figure shows us an example.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;figure&gt;
    &lt;div style=&quot;display: flex; flex-wrap: wrap; justify-content: center&quot;&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/9/9b/Human-Visible.jpg&quot; alt=&quot;Typical RGB image&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;Normal RGB image &lt;a href=&quot;https://en.wikipedia.org/wiki/Thermography#/media/File:Human-Visible.jpg&quot;&gt;(Image from Wikipedia)&lt;/a&gt;&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/4/44/Human-Infrared.jpg&quot; alt=&quot;Infrared image&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;Infrared image &lt;a href=&quot;https://en.wikipedia.org/wiki/Thermography#/media/File:Human-Infrared.jpg&quot;&gt;(Image from Wikipedia)&lt;/a&gt;&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;figcaption&gt;&lt;center&gt;RGB vs. infrared image&lt;/center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;Note that the infrared image only focusses on a single band and visualizes it as a &lt;em&gt;normal&lt;/em&gt; RGB image with an intensity scale next to it.
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;If we look at both the RGB and infrared images, we can combine them to get even more information!
The combination would count as a multi-spectral image. 
We do not limit ourselves to three visible light bands and can gain even more insights. What bands are sensed depends on the given sensor and the desired use-case.
For example, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sentinel-2&quot;&gt;Sentinel-2&lt;/a&gt; satellite takes multi-spectral images with 13 bands in the visible, near-infrared, and short wave infrared part of the spectrum. The next post will take a closer look at how we can load and visualize these remote images. But, before we move on, let's summarize what we have learned so far.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Summary&quot;&gt;Summary&lt;a class=&quot;anchor-link&quot; href=&quot;#Summary&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;We went from grayscale images with a single channel, to RGB images with three channels, to multi-spectral images with more than three channels. These multi-spectral images do not only focus on the visual-spectrum of electromagnetic waves but use even more bands. The main idea is that the information from different bands allows us to learn more about the object or scene.
In our previous example, we were able to verify that the person had five fingers on his left hand, even if we weren't able to see it from the visual-spectrum of the light. For my master thesis, I hope that
this additional information can be used in multi-spectral remote sensing
images to increase neural networks' accuracy and robustness further.&lt;/p&gt;
&lt;p&gt;But before we dive deep into neural networks, we first need to understand how we can visualize and work with these multi-spectral images, which will be the goal of the next post.&lt;/p&gt;
&lt;p&gt;Until then, have a productive time! :+1:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;div class=&quot;footnotes&quot;&gt;&lt;p id=&quot;fn-1&quot;&gt;1. For a more detailed comparison of additive vs. subtractive colors, see the blog post from &lt;a href=&quot;https://blog.thepapermillstore.com/color-theory-additive-subtractive-colors/&quot;&gt;thepapermillstore.com&lt;/a&gt;&lt;a href=&quot;#fnref-1&quot; class=&quot;footnote footnotes&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Introduction to grayscale images</title><link href="https://kai-tub.github.io/master-thesis-blog/images/2020/09/02/introduction.html" rel="alternate" type="text/html" title="Introduction to grayscale images" /><published>2020-09-02T00:00:00-05:00</published><updated>2020-09-02T00:00:00-05:00</updated><id>https://kai-tub.github.io/master-thesis-blog/images/2020/09/02/introduction</id><content type="html" xml:base="https://kai-tub.github.io/master-thesis-blog/images/2020/09/02/introduction.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-02-introduction.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;About&quot;&gt;About&lt;a class=&quot;anchor-link&quot; href=&quot;#About&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Before we can dive into multi-spectral satellite images, I think a quick refresher on how images
are encoded and represented in memory is a good starting point.&lt;/p&gt;
&lt;h2 id=&quot;Binary-encoding&quot;&gt;Binary encoding&lt;a class=&quot;anchor-link&quot; href=&quot;#Binary-encoding&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let's take a short recap of how classical computer vision images are encoded in memory.
Internally a computer (ignoring quantum-computing) only works with binary numbers. A binary number is either a 0 or a 1, on or off.
The value of such a binary number is called a &lt;em&gt;bit&lt;/em&gt;.
The smallest data-element is called a &lt;em&gt;byte&lt;/em&gt;. A byte consists of 8 bits.
There are different ways how we could use these 8 bits/1 byte to encode our data.
The data we are trying to store/load defines how we interpret the data. 
If we want to only work with positive integers, we use an unsigned integer type.
An unsigned integer with 8 bits can encode all numbers from 0$-$255.
If all bits are 1, also called &lt;em&gt;set&lt;/em&gt;, the value is 255.
If all bits are 0 the corresponding value is 0.&lt;sup id=&quot;fnref-1&quot; class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn-1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id=&quot;Grayscale-images&quot;&gt;Grayscale images&lt;a class=&quot;anchor-link&quot; href=&quot;#Grayscale-images&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Images, like everything in a computer, are also only encoded in binary values.
The most straightforward images are grayscale images. The possible colors of each pixel of a grayscale image can only range from black to gray to white, with all different gray shades in-between. 
&lt;em&gt;Pixels&lt;/em&gt; are the basic elements of a picture. The word itself, &lt;a href=&quot;https://en.wikipedia.org/wiki/Pixel#Etymology&quot;&gt;pixel&lt;/a&gt;, is a combination of the words picture and element/cell. So an image consists of pixels, similar to how a brick wall consists of bricks.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;figure&gt;
    &lt;div style=&quot;display: flex; flex-wrap: wrap; justify-content: center&quot;&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-02/brick.jpg&quot; alt=&quot;Brick&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;Pixel&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-02/brick-wall.jpg&quot; alt=&quot;Brick Wall&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;Complete Image&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;figcaption&gt;&lt;center&gt;My weird analogy&lt;/center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;&lt;p&gt;We can understand how simple 8-bit grayscale images are encoded with the knowledge of our previous simple encoding scheme.
The 8-bit refers to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Color_depth&quot;&gt;&lt;em&gt;color-depth&lt;/em&gt;&lt;/a&gt;. It indicates how many bits are used per channel.
We only have a single channel for a grayscale image, the
colors range from black to white. (We will take a closer look at different channels in the next post.)
For now, we note that our grayscale channel is encoded with 8-bits. Or, put differently, we use 8-bits for every pixel to show different shades of gray. With 8-bits, we can color each pixel in 256 (2⁸) different ways.&lt;/p&gt;
&lt;p&gt;With the &lt;a href=&quot;https://numpy.org/&quot;&gt;numpy&lt;/a&gt; and &lt;a href=&quot;https://pillow.readthedocs.io/&quot;&gt;PIL&lt;/a&gt; library,
we can easily create our own 8-bit grayscale image by merely changing the value of a byte.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;PIL&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageOps&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;to_grayscale_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;grayscale_8_bit_mode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;L&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grayscale_8_bit_mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;upscale_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEAREST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# PIL requires np arrays as input&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Datatype is uint8, our unsigned int consisting of 8-bits&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# zero is our single byte/value with value 0&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# -&amp;gt; Array has a width and height of 1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;zero&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;img_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;pixel_0&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zero&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;pixel_64&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zero&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;pixel_192&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zero&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;192&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;pixel_255&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zero&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_grayscale_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upscale_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bordered_img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageOps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;border&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;black&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# display(bordered_img) # To display in jupyter&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bordered_img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;2020-09-02/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.png&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;figure&gt;
    &lt;div style=&quot;display: flex; flex-wrap: wrap; justify-content: center&quot;&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-02/pixel_0.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;0&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-02/pixel_64.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;64&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-02/pixel_192.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;192&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-02/pixel_255.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;figcaption&gt;&lt;center&gt;255&lt;/center&gt;&lt;/figcaption&gt;
            &lt;/figure&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;figcaption&gt;&lt;center&gt;Visualization of different 8-bit grayscale pixel values&lt;/center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Until now, we did not care about the &lt;a href=&quot;https://en.wikipedia.org/wiki/Image_resolution#Pixel_resolution&quot;&gt;resolution&lt;/a&gt; of our images. 
The resolution defines how many pixels we use to visualize the object. A resolution of 1 corresponds to a single pixel.
But, with a single-pixel picture, we cannot retain a lot of information. As shown above, we could only create a single shade of gray.
Let's increase our resolution for the following images to a size of 224 pixels x 224 pixels. With more pixels, we can show more levels of detail.&lt;/p&gt;
&lt;p&gt;Now we can extend our previous code to draw gradients!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Using numpy&amp;#39;s broadcasting&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_grad_2d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_gradient&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_grad_2d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_gradient&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sum_grad_2d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_gradient&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;diff_grad_2d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_gradient&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Convert to a grayscale image as before&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# and save or show files&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;figure&gt;
    &lt;div style=&quot;display: flex; flex-wrap: wrap; justify-content: center&quot;&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-02/x_grad_2d.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-02/y_grad_2d.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-02/sum_grad_2d.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;/figure&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-02/diff_grad_2d.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;/figure&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;figcaption&gt;&lt;center&gt;Visualization of different 8-bit grayscale images&lt;/center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;If we don't limit ourselves to simple mathematical operations, we can show images with great detail.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;figure&gt;
        &lt;div&gt;
            &lt;figure&gt;
&lt;figure&gt;
  
    &lt;img class=&quot;docimage&quot; src=&quot;/master-thesis-blog/images/copied_from_nb/2020-09-02/peppers.png&quot; alt=&quot;&quot; /&gt;
    
    
&lt;/figure&gt;

            &lt;/figure&gt;
        &lt;/div&gt;
    &lt;figcaption&gt;&lt;center&gt;Typical test image&lt;/center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;div class=&quot;flash flash-warn&quot;&gt;
    &lt;svg class=&quot;octicon octicon-zap&quot; viewBox=&quot;0 0 10 16&quot; version=&quot;1.1&quot; width=&quot;10&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M10 7H6l3-7-9 9h4l-3 7 9-9z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Important: &lt;/strong&gt;Even if these images reveal a lot of information to us humans, in the end, they are only stored as 0s and 1s on the computer.
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The pepper's image consists of the following
values. Each value is saved as a single byte
on disk.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;array([[ 71,  96,  92, ..., 136, 132, 127],
       [ 87, 119, 113, ..., 181, 176, 170],
       [ 83, 114, 111, ..., 178, 174, 166],
       ...,
       [ 92, 120, 108, ..., 191, 198, 198],
       [ 88, 124, 104, ..., 202, 198, 194],
       [ 78, 126, 106, ..., 200, 193, 188]], dtype=uint8)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Increasing the number of pixels (resolution) allows us to encode more details. The color-depth shows us how many bits
we use per channel to encode a color. Our previous 8-bit grayscale pixel can, therefore, encode 256 different shades of gray. With a higher color-depth, we have access to more shades.
But what is when we want to enrich our image with colors?&lt;/p&gt;
&lt;p&gt;How to add colors to our image and how remote sensing images are different will be the topic of the next blog post!&lt;/p&gt;
&lt;p&gt;Until then, have a productive time! :+1:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;div class=&quot;footnotes&quot;&gt;&lt;p id=&quot;fn-1&quot;&gt;1. A quick refresher on how to translate binary numbers to unsigned integers can be found on &lt;a href=&quot;https://ryanstutorials.net/binary-tutorial/&quot;&gt;ryanstutorials&lt;/a&gt;&lt;a href=&quot;#fnref-1&quot; class=&quot;footnote footnotes&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry></feed>